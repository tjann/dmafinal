{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions_lemmatized = pd.read_csv('LemmatizedQuestions.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>QuestionUserId</th>\n",
       "      <th>QuestionCreateDate</th>\n",
       "      <th>QuestionScore</th>\n",
       "      <th>QuestionTitle</th>\n",
       "      <th>QuestionBody</th>\n",
       "      <th>NumAnswers</th>\n",
       "      <th>QuestionTitleAndBody</th>\n",
       "      <th>CodeText</th>\n",
       "      <th>TagFreeNonCodeText</th>\n",
       "      <th>CodeTextLemmatized</th>\n",
       "      <th>TagFreeNonCodeTextLemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['how', 'can', 'i', 'find', 'the', 'full', 'pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T17:01:58Z</td>\n",
       "      <td>27</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows? &lt;p&gt;I h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows? I have...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['get', 'a', 'preview', 'jpeg', 'of', 'a', 'pd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>535</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2008-08-02T18:43:54Z</td>\n",
       "      <td>40</td>\n",
       "      <td>Continuous Integration System for a Python Cod...</td>\n",
       "      <td>&lt;p&gt;I'm starting work on a hobby project with a...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Continuous Integration System for a Python Cod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Continuous Integration System for a Python Cod...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['continuous', 'integration', 'system', 'for',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>594</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2008-08-03T01:15:08Z</td>\n",
       "      <td>25</td>\n",
       "      <td>cx_Oracle: How do I iterate over a result set?</td>\n",
       "      <td>&lt;p&gt;There are several ways to iterate over a re...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cx_Oracle: How do I iterate over a result set?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cx_Oracle: How do I iterate over a result set?...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['cx_oracle', 'how', 'do', 'i', 'iterate', 'ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2008-08-03T13:19:16Z</td>\n",
       "      <td>28</td>\n",
       "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
       "      <td>&lt;p&gt;I don't remember whether I was dreaming or ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
       "      <td>foo in iter_attr(array of python objects, attr...</td>\n",
       "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
       "      <td>['foo', 'in', 'iter_attrarray', 'of', 'python'...</td>\n",
       "      <td>['using', 'in', 'to', 'match', 'an', 'attribut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QID  QuestionUserId    QuestionCreateDate  QuestionScore  \\\n",
       "0  469           147.0  2008-08-02T15:11:16Z             21   \n",
       "1  502           147.0  2008-08-02T17:01:58Z             27   \n",
       "2  535           154.0  2008-08-02T18:43:54Z             40   \n",
       "3  594           116.0  2008-08-03T01:15:08Z             25   \n",
       "4  683           199.0  2008-08-03T13:19:16Z             28   \n",
       "\n",
       "                                       QuestionTitle  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1            Get a preview JPEG of a PDF on Windows?   \n",
       "2  Continuous Integration System for a Python Cod...   \n",
       "3     cx_Oracle: How do I iterate over a result set?   \n",
       "4  Using 'in' to match an attribute of Python obj...   \n",
       "\n",
       "                                        QuestionBody  NumAnswers  \\\n",
       "0  <p>I am using the Photoshop's javascript API t...         4.0   \n",
       "1  <p>I have a cross-platform (Python) applicatio...         3.0   \n",
       "2  <p>I'm starting work on a hobby project with a...         7.0   \n",
       "3  <p>There are several ways to iterate over a re...         3.0   \n",
       "4  <p>I don't remember whether I was dreaming or ...         8.0   \n",
       "\n",
       "                                QuestionTitleAndBody  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1  Get a preview JPEG of a PDF on Windows? <p>I h...   \n",
       "2  Continuous Integration System for a Python Cod...   \n",
       "3  cx_Oracle: How do I iterate over a result set?...   \n",
       "4  Using 'in' to match an attribute of Python obj...   \n",
       "\n",
       "                                            CodeText  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  foo in iter_attr(array of python objects, attr...   \n",
       "\n",
       "                                  TagFreeNonCodeText  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1  Get a preview JPEG of a PDF on Windows? I have...   \n",
       "2  Continuous Integration System for a Python Cod...   \n",
       "3  cx_Oracle: How do I iterate over a result set?...   \n",
       "4  Using 'in' to match an attribute of Python obj...   \n",
       "\n",
       "                                  CodeTextLemmatized  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  ['foo', 'in', 'iter_attrarray', 'of', 'python'...   \n",
       "\n",
       "                        TagFreeNonCodeTextLemmatized  \n",
       "0  ['how', 'can', 'i', 'find', 'the', 'full', 'pa...  \n",
       "1  ['get', 'a', 'preview', 'jpeg', 'of', 'a', 'pd...  \n",
       "2  ['continuous', 'integration', 'system', 'for',...  \n",
       "3  ['cx_oracle', 'how', 'do', 'i', 'iterate', 'ov...  \n",
       "4  ['using', 'in', 'to', 'match', 'an', 'attribut...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "Transforming text to vectors:\n",
    "- Use tfidf\n",
    "- Use word2vec:\n",
    "    - Train non-code on 50D\n",
    "    - Train code on 50D\n",
    "    - Concatenate vectors\n",
    "\n",
    "\n",
    "\n",
    "After getting vector representation, use similarity metrics to find similar questions. Also hopefully use some clustering method is get cluster features for the feature engineering part.\n",
    "\n",
    "Similarity metrics:\n",
    "- top 10 most cosine similar\n",
    "\n",
    "Clustering method:\n",
    "- Maybe use DBscan\n",
    "- PCA or t-SNE\n",
    "- *The clustering method could possible indicate interesting sub-question types, e.g. one cluster is for non-code questions, another is for debugging, another is for conceptual.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Vector Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['how', 'can', 'i', 'find', 'the', 'full', 'path', 'to', 'a', 'font', 'from', 'it', 'display', 'name', 'on', 'a', 'mac', 'i', 'am', 'using', 'the', 'photoshops', 'javascript', 'api', 'to', 'find', 'the', 'font', 'in', 'a', 'given', 'psd', 'given', 'a', 'font', 'name', 'returned', 'by', 'the', 'api', 'i', 'want', 'to', 'find', 'the', 'actual', 'physical', 'font', 'file', 'that', 'that', 'font', 'name', 'corresponds', 'to', 'on', 'the', 'disc', 'this', 'is', 'all', 'happening', 'in', 'a', 'python', 'program', 'running', 'on', 'osx', 'so', 'i', 'guess', 'im', 'looking', 'for', 'one', 'of', 'some', 'photoshop', 'javascript', 'a', 'python', 'function', 'an', 'osx', 'api', 'that', 'i', 'can', 'call', 'from', 'python']\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_lemmatized[\"TagFreeNonCodeTextLemmatized\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Non-code text\n",
    "TagFreeNonCodeTextLemmatized = questions_lemmatized.TagFreeNonCodeTextLemmatized.tolist()\n",
    "TagFreeNonCodeTextLemmatized = [[w[1:-1] for w in q[1:-1].split(\", \")] for q in TagFreeNonCodeTextLemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code text\n",
    "CodeTextLemmatized = questions_lemmatized.CodeTextLemmatized.tolist()\n",
    "CodeTextLemmatized = [[w[1:-1] for w in q[1:-1].split(\", \")] for q in CodeTextLemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combined non-code and code\n",
    "AllTextLemmatized = []\n",
    "for i in range(len(TagFreeNonCodeTextLemmatized)):\n",
    "    noncode = TagFreeNonCodeTextLemmatized[i][:]\n",
    "    for w in CodeTextLemmatized[i]:\n",
    "        if w != '':\n",
    "            noncode.append(w)\n",
    "    AllTextLemmatized.append(\" \".join(noncode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how can i find the full path to a font from it display name on a mac i am using the photoshops javascript api to find the font in a given psd given a font name returned by the api i want to find the actual physical font file that that font name corresponds to on the disc this is all happening in a python program running on osx so i guess im looking for one of some photoshop javascript a python function an osx api that i can call from python'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllTextLemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tfidf\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000) # limit vocabulary size to 10,000\n",
    "tfidf_question = tfidf_vectorizer.fit_transform(AllTextLemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 187)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_question.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute cosine similarities of questions\n",
    "tfidf_question_cosine_similarities = [] # list of indices of top 10 most cosine similar\n",
    "for i in range(len(questions_lemmatized.index)):\n",
    "    similarity_indices = cosine_similarity(AllTextLemmatized[i], AllTextLemmatized).flatten()\n",
    "    tfidf_question_cosine_similarities.append(similarity_indices.argsort()[:-11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_question_cosine_similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to df\n",
    "tfidf_df = pd.DataFrame((_ for _ in itertools.zip_longest(tfidf_question_cosine_similarities)), columns=['indices'])\n",
    "tfidf_df.to_pickle(\"TfIdfSimilarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2vec for non-code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import tokenize\n",
    "from nltk.data import find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word2vec model for non-code text\n",
    "noncode_model = gensim.models.Word2Vec(TagFreeNonCodeTextLemmatized, min_count=10, size=50, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173066"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noncode_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noncode_unique_words = {}\n",
    "for q in TagFreeNonCodeTextLemmatized:\n",
    "    for w in q:\n",
    "        if not noncode_unique_words.get(w):\n",
    "            noncode_unique_words[w] = 0\n",
    "        noncode_unique_words[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4806582"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(noncode_unique_words.keys())\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get word vectors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word vectors\n",
    "noncode_vector_list=[] ## n by d matrix containing words and their respective vectors\n",
    "for word, cnt in noncode_unique_words.items():\n",
    "    if cnt >= 10:\n",
    "        noncode_vector_list.append(noncode_model[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(noncode_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "noncode_model.save(\"noncode_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "noncode_model = Word2Vec.load(\"noncode_word2vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Sum up word vectors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "noncode_q_embedding = []\n",
    "for q in TagFreeNonCodeTextLemmatized:\n",
    "    q_embedding = np.zeros(50)\n",
    "    for word in q:\n",
    "        if noncode_unique_words[word] > 10:\n",
    "            q_embedding += noncode_model[word]\n",
    "    noncode_q_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(noncode_q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 104.7903592 ,  233.98276646, -187.92552194,  218.95368098,\n",
       "        123.9839341 ,  210.74747539, -125.32897924,  -59.38568768,\n",
       "        220.99190462,  165.27572969,  309.69482501,   70.60778694,\n",
       "        -89.19382327,  171.32715937,  105.65731641,  197.60346127,\n",
       "       -338.3882495 , -124.68667492,   93.64890997, -136.77202329,\n",
       "          3.47088823, -238.19950062,   -8.11581397,   99.49042188,\n",
       "        -99.58810435,  -27.32146006,   74.11278299,  -92.9729311 ,\n",
       "       -134.64065651,  -29.21850541, -146.18743266,  103.05293993,\n",
       "        112.29461885,   -9.56411882,  153.76655305,  128.6384503 ,\n",
       "        210.67027523,   77.33066313, -174.92864283,  431.12630757,\n",
       "       -124.75030518, -179.11365573,  -12.35419412, -166.64131038,\n",
       "         92.66414439,  371.69936726,   17.02718088,  -12.97852471,\n",
       "        -22.40040434,  -81.81657255])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncode_q_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noncode_embedding_df = pd.DataFrame((_ for _ in itertools.zip_longest(noncode_q_embedding)), columns=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[104.790359199, 233.982766459, -187.925521936, 218.953680977, 123.983934097, 210.747475386, -125.328979243, -59.3856876823, 220.991904616, 165.275729688, 309.694825012, 70.6077869423, -89.1938232686, 171.327159369, 105.657316407, 197.603461273, -338.388249498, -124.686674917, 93.6489099711, -136.772023287, 3.47088822583, -238.19950062, -8.11581396684, 99.4904218763, -99.5881043486, -27.3214600593, 74.1127829906, -92.9729310954, -134.640656512, -29.2185054142, -146.18743266, 103.052939931, 112.294618849, -9.5641188249, 153.766553048, 128.638450302, 210.670275226, 77.3306631297, -174.928642828, 431.126307566, -124.750305183, -179.113655731, -12.3541941196, -166.641310379, 92.6641443931, 371.699367259, 17.0271808766, -12.9785247147, -22.4004043401, -81.816572547]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[55.3639270877, 133.266654551, -86.4549356252, 111.066199854, 56.2065773308, 81.6096022394, -72.7127401382, 1.670049496, 136.604849696, 95.3309267713, 138.269164908, 36.2933272626, -67.986693738, 98.9401275218, 42.8894385993, 103.230953047, -174.11741139, -62.7397340573, 50.3225486279, -90.0264730081, 4.83511715708, -92.8561457992, -19.9641806073, 72.5665770173, -56.6354180798, -15.1344212517, 36.8711684793, -34.182656683, -69.5725146532, -40.1553565077, -48.4681739286, 66.2455350407, 74.6280928254, -16.4468314983, 72.8434932679, 62.0341959745, 97.4522367325, 35.6087533683, -87.9680896625, 173.25405623, -45.824375689, -102.198631518, -27.1955427527, -99.1857887208, 58.5275302026, 189.914759338, 20.0960416943, -0.826119460166, -20.63310498, -22.029436633]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[54.3329749852, 285.638077168, -152.193748194, 252.458389223, 135.816546923, 141.300634113, -175.035026833, -114.694900859, 303.978268006, 179.963486716, 325.111237824, 105.57181856, -71.8182222936, 193.591465889, 93.8829704337, 168.555061277, -347.770992223, -153.820742648, 66.3441991098, -142.69999681, 37.9139700402, -212.810971618, -43.178185062, 78.8426956832, -105.175491161, 13.1848163671, 96.8504572809, -30.3039049134, -201.770106144, -25.0391419306, -89.9095067829, 102.289408068, 170.157912962, -117.453764483, 177.206255246, 63.4345086552, 195.50388794, 93.9019377902, -207.720366579, 435.319405917, -111.861734318, -239.765813738, -3.39318139665, -174.95971073, 76.7553634811, 392.404411126, 20.3921948206, -42.5436140969, 21.7911405712, -75.4819956459]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4.21130882017, 81.7820248604, -45.8087611794, 43.7592364363, 31.3608980179, 13.3545329273, -64.6297825575, -37.2147189528, 53.1147626042, 62.0836489797, 83.6681051254, 2.68432169635, -21.7842616625, 31.0639320556, 3.15348035097, 63.45482409, -71.2471692837, -7.54581606388, 18.4726314247, -36.0588860922, 23.5224828215, -77.0910546482, -11.2327012978, 12.6795762107, -37.4683555514, -7.52302828431, 52.3168457896, -23.5711653307, -43.2639132887, -11.5316375047, -34.3603463322, 0.451465785503, 25.1488592923, 0.524699300528, 40.1025175452, 43.7749269903, 72.2718237936, -3.71755111217, -73.9268929064, 148.108174264, -26.8722826391, -71.5127802566, -12.7309114337, 10.1754982471, 10.039438128, 87.3739898652, -0.976289086044, -1.06623494253, 17.3094673902, -14.2749106139]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-7.63487214409, 119.273091219, -119.881945048, 92.4632230382, 59.3196130246, 56.0633011237, -53.1829489504, -62.8890879974, 138.21860069, 108.050570503, 172.774720511, 21.5010277443, -34.9738803543, 108.472790748, 90.9307340998, 63.5067607388, -173.108571775, -37.7602649368, 60.1650732234, -75.7864731476, 35.4305654073, -143.201133817, -4.63866125105, 29.6932117119, -68.0734032243, -24.0540987961, 101.841362187, -46.643446248, -99.5825744122, -24.724611789, -100.854048193, 13.8610689417, 54.4688177705, -1.80633024871, 74.715627145, 61.1358464062, 102.231919112, 40.1402136988, -88.2506073974, 244.023586661, -58.5301206335, -108.962415516, -10.9627735007, -57.6790872961, 0.268351402134, 158.562287971, -20.9483304489, -72.3811652362, -3.95506547391, -38.4660156369]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               embedding\n",
       "0  [104.790359199, 233.982766459, -187.925521936, 218.953680977, 123.983934097, 210.747475386, -125.328979243, -59.3856876823, 220.991904616, 165.275729688, 309.694825012, 70.6077869423, -89.1938232686, 171.327159369, 105.657316407, 197.603461273, -338.388249498, -124.686674917, 93.6489099711, -136.772023287, 3.47088822583, -238.19950062, -8.11581396684, 99.4904218763, -99.5881043486, -27.3214600593, 74.1127829906, -92.9729310954, -134.640656512, -29.2185054142, -146.18743266, 103.052939931, 112.294618849, -9.5641188249, 153.766553048, 128.638450302, 210.670275226, 77.3306631297, -174.928642828, 431.126307566, -124.750305183, -179.113655731, -12.3541941196, -166.641310379, 92.6641443931, 371.699367259, 17.0271808766, -12.9785247147, -22.4004043401, -81.816572547]   \n",
       "1  [55.3639270877, 133.266654551, -86.4549356252, 111.066199854, 56.2065773308, 81.6096022394, -72.7127401382, 1.670049496, 136.604849696, 95.3309267713, 138.269164908, 36.2933272626, -67.986693738, 98.9401275218, 42.8894385993, 103.230953047, -174.11741139, -62.7397340573, 50.3225486279, -90.0264730081, 4.83511715708, -92.8561457992, -19.9641806073, 72.5665770173, -56.6354180798, -15.1344212517, 36.8711684793, -34.182656683, -69.5725146532, -40.1553565077, -48.4681739286, 66.2455350407, 74.6280928254, -16.4468314983, 72.8434932679, 62.0341959745, 97.4522367325, 35.6087533683, -87.9680896625, 173.25405623, -45.824375689, -102.198631518, -27.1955427527, -99.1857887208, 58.5275302026, 189.914759338, 20.0960416943, -0.826119460166, -20.63310498, -22.029436633]         \n",
       "2  [54.3329749852, 285.638077168, -152.193748194, 252.458389223, 135.816546923, 141.300634113, -175.035026833, -114.694900859, 303.978268006, 179.963486716, 325.111237824, 105.57181856, -71.8182222936, 193.591465889, 93.8829704337, 168.555061277, -347.770992223, -153.820742648, 66.3441991098, -142.69999681, 37.9139700402, -212.810971618, -43.178185062, 78.8426956832, -105.175491161, 13.1848163671, 96.8504572809, -30.3039049134, -201.770106144, -25.0391419306, -89.9095067829, 102.289408068, 170.157912962, -117.453764483, 177.206255246, 63.4345086552, 195.50388794, 93.9019377902, -207.720366579, 435.319405917, -111.861734318, -239.765813738, -3.39318139665, -174.95971073, 76.7553634811, 392.404411126, 20.3921948206, -42.5436140969, 21.7911405712, -75.4819956459]      \n",
       "3  [4.21130882017, 81.7820248604, -45.8087611794, 43.7592364363, 31.3608980179, 13.3545329273, -64.6297825575, -37.2147189528, 53.1147626042, 62.0836489797, 83.6681051254, 2.68432169635, -21.7842616625, 31.0639320556, 3.15348035097, 63.45482409, -71.2471692837, -7.54581606388, 18.4726314247, -36.0588860922, 23.5224828215, -77.0910546482, -11.2327012978, 12.6795762107, -37.4683555514, -7.52302828431, 52.3168457896, -23.5711653307, -43.2639132887, -11.5316375047, -34.3603463322, 0.451465785503, 25.1488592923, 0.524699300528, 40.1025175452, 43.7749269903, 72.2718237936, -3.71755111217, -73.9268929064, 148.108174264, -26.8722826391, -71.5127802566, -12.7309114337, 10.1754982471, 10.039438128, 87.3739898652, -0.976289086044, -1.06623494253, 17.3094673902, -14.2749106139]\n",
       "4  [-7.63487214409, 119.273091219, -119.881945048, 92.4632230382, 59.3196130246, 56.0633011237, -53.1829489504, -62.8890879974, 138.21860069, 108.050570503, 172.774720511, 21.5010277443, -34.9738803543, 108.472790748, 90.9307340998, 63.5067607388, -173.108571775, -37.7602649368, 60.1650732234, -75.7864731476, 35.4305654073, -143.201133817, -4.63866125105, 29.6932117119, -68.0734032243, -24.0540987961, 101.841362187, -46.643446248, -99.5825744122, -24.724611789, -100.854048193, 13.8610689417, 54.4688177705, -1.80633024871, 74.715627145, 61.1358464062, 102.231919112, 40.1402136988, -88.2506073974, 244.023586661, -58.5301206335, -108.962415516, -10.9627735007, -57.6790872961, 0.268351402134, 158.562287971, -20.9483304489, -72.3811652362, -3.95506547391, -38.4660156369]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncode_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df\n",
    "noncode_embedding_df.to_pickle(\"NoncodeTextWordEmbeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2vec for code text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec model for code text\n",
    "code_model = gensim.models.Word2Vec(CodeTextLemmatized, min_count=10, size=50, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(code_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get set of unique words and counts\n",
    "code_unique_words = {}\n",
    "for q in CodeTextLemmatized:\n",
    "    for w in q:\n",
    "        if not code_unique_words.get(w):\n",
    "            code_unique_words[w] = 0\n",
    "        code_unique_words[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "code_model.save(\"code_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "code_model = Word2Vec.load(\"code_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum up word vectors\n",
    "code_q_embedding = []\n",
    "for q in CodeTextLemmatized:\n",
    "    q_embedding = np.zeros(50)\n",
    "    for word in q:\n",
    "        if code_unique_words[word] > 10:\n",
    "            q_embedding += code_model[word]\n",
    "    code_q_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(code_q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_embedding_df = pd.DataFrame((_ for _ in itertools.zip_longest(code_q_embedding)), columns=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'code_embedding_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-ef9724a73750>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcode_embedding_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'code_embedding_df' is not defined"
     ]
    }
   ],
   "source": [
    "code_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df\n",
    "code_embedding_df.to_pickle(\"CodeTextWordEmbeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get top 10 most cosine similar questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Concatenate code and non-code embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_embedding = []\n",
    "for i in range(len(noncode_q_embedding)):\n",
    "    q_embedding = np.concatenate(noncode_q_embedding[i], code_q_embedding[i])\n",
    "    combined_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(combined_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_embedding[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get top 10 most cosine similar word embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "word2vec_cosine_similarities = []\n",
    "for i in range(len(combined_embedding)):\n",
    "    word2vec_cosine_similarities.append(cosine_similarity(combined_embedding[i], combined_embedding).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to df\n",
    "word2vec_similarity_df = pd.DataFrame((_ for _ in itertools.zip_longest(word2vec_cosine_similarities)), columns=['indices'])\n",
    "word2vec_similarity_df.to_pickle(\"word2vecSimilarity\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
