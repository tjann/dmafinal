{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_lemmatized = pd.read_csv('LemmatizedQuestions.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>QuestionUserId</th>\n",
       "      <th>QuestionCreateDate</th>\n",
       "      <th>QuestionScore</th>\n",
       "      <th>QuestionTitle</th>\n",
       "      <th>QuestionBody</th>\n",
       "      <th>NumAnswers</th>\n",
       "      <th>QuestionTitleAndBody</th>\n",
       "      <th>CodeText</th>\n",
       "      <th>TagFreeNonCodeText</th>\n",
       "      <th>CodeTextLemmatized</th>\n",
       "      <th>TagFreeNonCodeTextLemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T15:11:16Z</td>\n",
       "      <td>21</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>&lt;p&gt;I am using the Photoshop's javascript API t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['how', 'can', 'i', 'find', 'the', 'full', 'pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2008-08-02T17:01:58Z</td>\n",
       "      <td>27</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>&lt;p&gt;I have a cross-platform (Python) applicatio...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows? &lt;p&gt;I h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows? I have...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['get', 'a', 'preview', 'jpeg', 'of', 'a', 'pd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>535</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2008-08-02T18:43:54Z</td>\n",
       "      <td>40</td>\n",
       "      <td>Continuous Integration System for a Python Cod...</td>\n",
       "      <td>&lt;p&gt;I'm starting work on a hobby project with a...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Continuous Integration System for a Python Cod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Continuous Integration System for a Python Cod...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['continuous', 'integration', 'system', 'for',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>594</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2008-08-03T01:15:08Z</td>\n",
       "      <td>25</td>\n",
       "      <td>cx_Oracle: How do I iterate over a result set?</td>\n",
       "      <td>&lt;p&gt;There are several ways to iterate over a re...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cx_Oracle: How do I iterate over a result set?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cx_Oracle: How do I iterate over a result set?...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['cx_oracle', 'how', 'do', 'i', 'iterate', 'ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2008-08-03T13:19:16Z</td>\n",
       "      <td>28</td>\n",
       "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
       "      <td>&lt;p&gt;I don't remember whether I was dreaming or ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
       "      <td>foo in iter_attr(array of python objects, attr...</td>\n",
       "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
       "      <td>['foo', 'in', 'iter_attrarray', 'of', 'python'...</td>\n",
       "      <td>['using', 'in', 'to', 'match', 'an', 'attribut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QID  QuestionUserId    QuestionCreateDate  QuestionScore  \\\n",
       "0  469           147.0  2008-08-02T15:11:16Z             21   \n",
       "1  502           147.0  2008-08-02T17:01:58Z             27   \n",
       "2  535           154.0  2008-08-02T18:43:54Z             40   \n",
       "3  594           116.0  2008-08-03T01:15:08Z             25   \n",
       "4  683           199.0  2008-08-03T13:19:16Z             28   \n",
       "\n",
       "                                       QuestionTitle  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1            Get a preview JPEG of a PDF on Windows?   \n",
       "2  Continuous Integration System for a Python Cod...   \n",
       "3     cx_Oracle: How do I iterate over a result set?   \n",
       "4  Using 'in' to match an attribute of Python obj...   \n",
       "\n",
       "                                        QuestionBody  NumAnswers  \\\n",
       "0  <p>I am using the Photoshop's javascript API t...         4.0   \n",
       "1  <p>I have a cross-platform (Python) applicatio...         3.0   \n",
       "2  <p>I'm starting work on a hobby project with a...         7.0   \n",
       "3  <p>There are several ways to iterate over a re...         3.0   \n",
       "4  <p>I don't remember whether I was dreaming or ...         8.0   \n",
       "\n",
       "                                QuestionTitleAndBody  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1  Get a preview JPEG of a PDF on Windows? <p>I h...   \n",
       "2  Continuous Integration System for a Python Cod...   \n",
       "3  cx_Oracle: How do I iterate over a result set?...   \n",
       "4  Using 'in' to match an attribute of Python obj...   \n",
       "\n",
       "                                            CodeText  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  foo in iter_attr(array of python objects, attr...   \n",
       "\n",
       "                                  TagFreeNonCodeText  \\\n",
       "0  How can I find the full path to a font from it...   \n",
       "1  Get a preview JPEG of a PDF on Windows? I have...   \n",
       "2  Continuous Integration System for a Python Cod...   \n",
       "3  cx_Oracle: How do I iterate over a result set?...   \n",
       "4  Using 'in' to match an attribute of Python obj...   \n",
       "\n",
       "                                  CodeTextLemmatized  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  ['foo', 'in', 'iter_attrarray', 'of', 'python'...   \n",
       "\n",
       "                        TagFreeNonCodeTextLemmatized  \n",
       "0  ['how', 'can', 'i', 'find', 'the', 'full', 'pa...  \n",
       "1  ['get', 'a', 'preview', 'jpeg', 'of', 'a', 'pd...  \n",
       "2  ['continuous', 'integration', 'system', 'for',...  \n",
       "3  ['cx_oracle', 'how', 'do', 'i', 'iterate', 'ov...  \n",
       "4  ['using', 'in', 'to', 'match', 'an', 'attribut...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "Transforming text to vectors:\n",
    "- Use tfidf\n",
    "- Use word2vec:\n",
    "    - Train non-code on 50D\n",
    "    - Train code on 50D\n",
    "    - Concatenate vectors\n",
    "\n",
    "\n",
    "\n",
    "After getting vector representation, use similarity metrics to find similar questions. Also hopefully use some clustering method is get cluster features for the feature engineering part.\n",
    "\n",
    "Similarity metrics:\n",
    "- top 10 most cosine similar\n",
    "\n",
    "Clustering method:\n",
    "- Maybe use DBscan\n",
    "- PCA or t-SNE\n",
    "- *The clustering method could possible indicate interesting sub-question types, e.g. one cluster is for non-code questions, another is for debugging, another is for conceptual.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Vector Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_lemmatized[\"TagFreeNonCodeTextLemmatized\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Non-code text\n",
    "TagFreeNonCodeTextLemmatized = questions_lemmatized.TagFreeNonCodeTextLemmatized.tolist()\n",
    "TagFreeNonCodeTextLemmatized = [[w[1:-1] for w in q[1:-1].split(\", \")] for q in TagFreeNonCodeTextLemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code text\n",
    "CodeTextLemmatized = questions_lemmatized.CodeTextLemmatized.tolist()\n",
    "CodeTextLemmatized = [[w[1:-1] for w in q[1:-1].split(\", \")] for q in CodeTextLemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combined non-code and code\n",
    "AllTextLemmatized = []\n",
    "for i in range(len(TagFreeNonCodeTextLemmatized)):\n",
    "    noncode = TagFreeNonCodeTextLemmatized[i][:]\n",
    "    for w in CodeTextLemmatized[i]:\n",
    "        if w != '':\n",
    "            noncode.append(w)\n",
    "    AllTextLemmatized.append(\" \".join(noncode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllTextLemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tfidf\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000) # limit vocabulary size to 10,000\n",
    "tfidf_question = tfidf_vectorizer.fit_transform(AllTextLemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_question.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute cosine similarities of questions\n",
    "tfidf_question_cosine_similarities = [] # list of indices of top 10 most cosine similar\n",
    "for i in range(len(questions_lemmatized.index)):\n",
    "    similarity_indices = cosine_similarity(tfidf_question[i], tfidf_question).flatten()\n",
    "    tfidf_question_cosine_similarities.append(similarity_indices.argsort()[:-11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_question_cosine_similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to df\n",
    "tfidf_df = pd.DataFrame((_ for _ in itertools.zip_longest(tfidf_question_cosine_similarities)), columns=['indices'])\n",
    "tfidf_df.to_pickle(\"TfIdfSimilarity.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2vec for non-code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import tokenize\n",
    "from nltk.data import find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec model for non-code text\n",
    "noncode_model = gensim.models.Word2Vec(TagFreeNonCodeTextLemmatized, min_count=10, size=50, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(noncode_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_unique_words = {}\n",
    "for q in TagFreeNonCodeTextLemmatized:\n",
    "    for w in q:\n",
    "        if not noncode_unique_words.get(w):\n",
    "            noncode_unique_words[w] = 0\n",
    "        noncode_unique_words[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = list(noncode_unique_words.keys())\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get word vectors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word vectors\n",
    "noncode_vector_list=[] ## n by d matrix containing words and their respective vectors\n",
    "for word, cnt in noncode_unique_words.items():\n",
    "    if cnt >= 10:\n",
    "        noncode_vector_list.append(noncode_model[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(noncode_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "noncode_model.save(\"noncode_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "noncode_model = gensim.models.Word2Vec.load(\"noncode_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Sum up word vectors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_q_embedding = []\n",
    "for q in TagFreeNonCodeTextLemmatized:\n",
    "    q_embedding = np.zeros(50)\n",
    "    for word in q:\n",
    "        if noncode_unique_words[word] > 10:\n",
    "            q_embedding += noncode_model[word]\n",
    "    noncode_q_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(noncode_q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_q_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noncode_embedding_df = pd.DataFrame((_ for _ in itertools.zip_longest(noncode_q_embedding)), columns=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df\n",
    "noncode_embedding_df.to_pickle(\"NoncodeTextWordEmbeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2vec for code text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec model for code text\n",
    "code_model = gensim.models.Word2Vec(CodeTextLemmatized, min_count=10, size=50, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(code_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get set of unique words and counts\n",
    "code_unique_words = {}\n",
    "for q in CodeTextLemmatized:\n",
    "    for w in q:\n",
    "        if not code_unique_words.get(w):\n",
    "            code_unique_words[w] = 0\n",
    "        code_unique_words[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "code_model.save(\"code_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "code_model = gensim.models.Word2Vec.load(\"code_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum up word vectors\n",
    "code_q_embedding = []\n",
    "for q in CodeTextLemmatized:\n",
    "    q_embedding = np.zeros(50)\n",
    "    for word in q:\n",
    "        if code_unique_words[word] > 10:\n",
    "            q_embedding += code_model[word]\n",
    "    code_q_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(code_q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_embedding_df = pd.DataFrame((_ for _ in itertools.zip_longest(code_q_embedding)), columns=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df\n",
    "code_embedding_df.to_pickle(\"CodeTextWordEmbeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get top 10 most cosine similar questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Concatenate code and non-code embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_embedding = []\n",
    "for i in range(noncode_embedding_df.shape[0]):\n",
    "    q_embedding = np.append(noncode_embedding_df.iloc[i,:], code_embedding_df.iloc[i,:])\n",
    "    combined_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get top 10 most cosine similar word embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-2.33485798e+02,  1.34262846e+02, -1.61999403e+02,  2.75851354e+02,\n",
       "        3.92991432e+01,  1.65180587e+01,  8.67004336e+01, -2.02523277e+02,\n",
       "        6.78854387e+01,  2.48089458e+01, -1.48255976e+02,  2.34974266e+01,\n",
       "        1.19403369e+02, -2.44532929e+02, -2.74176350e+02,  1.36803860e+02,\n",
       "        2.13601728e+02,  2.29295494e+02, -1.56278791e+02,  2.11458459e-01,\n",
       "        6.56653517e+01, -3.22754556e+02,  2.31872174e+02, -3.21034162e+02,\n",
       "        1.81830842e-01, -2.67967392e+02, -6.48300108e+01, -6.94139397e+01,\n",
       "       -1.22944525e+02, -1.67904527e+02, -1.01985767e+02,  7.37741048e+01,\n",
       "       -6.98878253e+01, -1.52692972e+02,  1.63893139e+02,  5.44709623e+01,\n",
       "        2.20797490e+02, -1.64560005e+02,  1.35766674e+01, -1.22989319e+02,\n",
       "       -6.49815582e+01, -4.90088749e+01,  2.48694221e+02,  9.59186933e+01,\n",
       "        2.46383301e+02,  2.01767801e+02, -3.64020447e+01, -7.09914588e+01,\n",
       "       -1.31085836e+02, -9.55905345e+01]),\n",
       "       array([ 0.00583147,  0.00644809, -0.0066126 ,  0.00494719, -0.00115847,\n",
       "        0.0095309 ,  0.00880876, -0.00926695,  0.00309273, -0.00979174,\n",
       "        0.00768982,  0.00726122,  0.00661461, -0.00101699,  0.00493398,\n",
       "       -0.00394094,  0.00524924, -0.00911956, -0.00733663,  0.00914222,\n",
       "       -0.00361557, -0.00186858, -0.00013569,  0.00037513, -0.00268484,\n",
       "       -0.00945437,  0.0010926 ,  0.00237037,  0.00076781, -0.00381351,\n",
       "        0.00673612,  0.00530561,  0.00755437, -0.00704698,  0.00808137,\n",
       "       -0.00546271, -0.00342319,  0.00657532, -0.00331153, -0.00237883,\n",
       "       -0.00239633, -0.00173464,  0.00090926,  0.00841918, -0.00633817,\n",
       "       -0.00661265, -0.00737416, -0.0053381 , -0.00373118, -0.00967743])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7788a37dc730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mword2vec_question_cosine_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msimilarity_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mword2vec_question_cosine_similarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m--> 110\u001b[0;31m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[0m\u001b[1;32m    111\u001b[0m         Y = check_array(Y, accept_sparse='csr', dtype=dtype,\n\u001b[1;32m    112\u001b[0m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# compute cosine similarities of questions\n",
    "# tfidf_question_cosine_similarities = [] # list of indices of top 10 most cosine similar\n",
    "# for i in range(len(questions_lemmatized.index)):\n",
    "#     similarity_indices = cosine_similarity(tfidf_question[i], tfidf_question).flatten()\n",
    "#     tfidf_question_cosine_similarities.append(similarity_indices.argsort()[:-11:-1])\n",
    "\n",
    "\n",
    "# list of indices of top 10 most cosine similar for each question\n",
    "word2vec_question_cosine_similarities = []\n",
    "for i in range(len(combined_embedding)):\n",
    "    similarity_indices = cosine_similarity(combined_embedding[i], combined_embedding).flatten()\n",
    "    word2vec_question_cosine_similarities.append(similarity_indices[i].argsort()[:-11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_question_cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to df\n",
    "word2vec_similarity_df = pd.DataFrame((_ for _ in itertools.zip_longest(word2vec_cosine_similarities)), columns=['indices'])\n",
    "word2vec_similarity_df.to_pickle(\"word2vecSimilarity.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
