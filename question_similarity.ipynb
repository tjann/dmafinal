{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THESE CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_embedding_df = pd.read_pickle(\"NoncodeTextWordEmbeddings\")\n",
    "code_embedding_df = pd.read_pickle(\"CodeTextWordEmbeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_embedding = []\n",
    "for i in range(noncode_embedding_df.shape[0]):\n",
    "    q_embedding = np.append(noncode_embedding_df.iloc[i,:][0], code_embedding_df.iloc[i,:][0])\n",
    "    combined_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_embedding_df = pd.DataFrame((_ for _ in itertools.zip_longest(combined_embedding)), columns=['indices'])\n",
    "combined_embedding_df.to_pickle(\"CombinedWordEmbeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kimberly\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# list of indices of top 10 most cosine similar for each question\n",
    "word2vec_question_cosine_similarities = []\n",
    "for i in range(len(combined_embedding)):\n",
    "    similarity_indices = cosine_similarity(combined_embedding[i], combined_embedding).flatten()\n",
    "    word2vec_question_cosine_similarities.append(similarity_indices.argsort()[:-11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to df\n",
    "word2vec_similarity_df = pd.DataFrame((_ for _ in itertools.zip_longest(word2vec_question_cosine_similarities)), columns=['indices'])\n",
    "word2vec_similarity_df.to_pickle(\"word2vecSimilarity.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY RUN CELLS ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_lemmatized = pd.read_csv('LemmatizedQuestions.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "Transforming text to vectors:\n",
    "- Use tfidf\n",
    "- Use word2vec:\n",
    "    - Train non-code on 50D\n",
    "    - Train code on 50D\n",
    "    - Concatenate vectors\n",
    "\n",
    "\n",
    "\n",
    "After getting vector representation, use similarity metrics to find similar questions. Also hopefully use some clustering method is get cluster features for the feature engineering part.\n",
    "\n",
    "Similarity metrics:\n",
    "- top 10 most cosine similar\n",
    "\n",
    "Clustering method:\n",
    "- Maybe use DBscan\n",
    "- PCA or t-SNE\n",
    "- *The clustering method could possible indicate interesting sub-question types, e.g. one cluster is for non-code questions, another is for debugging, another is for conceptual.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Vector Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_lemmatized[\"TagFreeNonCodeTextLemmatized\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Non-code text\n",
    "TagFreeNonCodeTextLemmatized = questions_lemmatized.TagFreeNonCodeTextLemmatized.tolist()\n",
    "TagFreeNonCodeTextLemmatized = [[w[1:-1] for w in q[1:-1].split(\", \")] for q in TagFreeNonCodeTextLemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code text\n",
    "CodeTextLemmatized = questions_lemmatized.CodeTextLemmatized.tolist()\n",
    "CodeTextLemmatized = [[w[1:-1] for w in q[1:-1].split(\", \")] for q in CodeTextLemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combined non-code and code\n",
    "AllTextLemmatized = []\n",
    "for i in range(len(TagFreeNonCodeTextLemmatized)):\n",
    "    noncode = TagFreeNonCodeTextLemmatized[i][:]\n",
    "    for w in CodeTextLemmatized[i]:\n",
    "        if w != '':\n",
    "            noncode.append(w)\n",
    "    AllTextLemmatized.append(\" \".join(noncode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllTextLemmatized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tfidf\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000) # limit vocabulary size to 10,000\n",
    "tfidf_question = tfidf_vectorizer.fit_transform(AllTextLemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_question.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute cosine similarities of questions\n",
    "tfidf_question_cosine_similarities = [] # list of indices of top 10 most cosine similar\n",
    "for i in range(len(questions_lemmatized.index)):\n",
    "    similarity_indices = cosine_similarity(tfidf_question[i], tfidf_question).flatten()\n",
    "    tfidf_question_cosine_similarities.append(similarity_indices.argsort()[:-11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_question_cosine_similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to df\n",
    "tfidf_df = pd.DataFrame((_ for _ in itertools.zip_longest(tfidf_question_cosine_similarities)), columns=['indices'])\n",
    "tfidf_df.to_pickle(\"TfIdfSimilarity.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdfidf_df = pd.read_pickle(\"TfIdfSimilarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2vec for non-code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import tokenize\n",
    "from nltk.data import find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec model for non-code text\n",
    "noncode_model = gensim.models.Word2Vec(TagFreeNonCodeTextLemmatized, min_count=10, size=50, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(noncode_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_unique_words = {}\n",
    "for q in TagFreeNonCodeTextLemmatized:\n",
    "    for w in q:\n",
    "        if not noncode_unique_words.get(w):\n",
    "            noncode_unique_words[w] = 0\n",
    "        noncode_unique_words[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = list(noncode_unique_words.keys())\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get word vectors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Word vectors\n",
    "noncode_vector_list=[] ## n by d matrix containing words and their respective vectors\n",
    "for word, cnt in noncode_unique_words.items():\n",
    "    if cnt >= 10:\n",
    "        noncode_vector_list.append(noncode_model[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(noncode_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "noncode_model.save(\"noncode_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "noncode_model = gensim.models.Word2Vec.load(\"noncode_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Sum up word vectors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_q_embedding = []\n",
    "for q in TagFreeNonCodeTextLemmatized:\n",
    "    q_embedding = np.zeros(50)\n",
    "    for word in q:\n",
    "        if noncode_unique_words[word] > 10:\n",
    "            q_embedding += noncode_model[word]\n",
    "    noncode_q_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(noncode_q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_q_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noncode_embedding_df = pd.DataFrame((_ for _ in itertools.zip_longest(noncode_q_embedding)), columns=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df\n",
    "noncode_embedding_df.to_pickle(\"NoncodeTextWordEmbeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2vec for code text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec model for code text\n",
    "code_model = gensim.models.Word2Vec(CodeTextLemmatized, min_count=10, size=50, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(code_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get set of unique words and counts\n",
    "code_unique_words = {}\n",
    "for q in CodeTextLemmatized:\n",
    "    for w in q:\n",
    "        if not code_unique_words.get(w):\n",
    "            code_unique_words[w] = 0\n",
    "        code_unique_words[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "code_model.save(\"code_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "code_model = gensim.models.Word2Vec.load(\"code_word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum up word vectors\n",
    "code_q_embedding = []\n",
    "for q in CodeTextLemmatized:\n",
    "    q_embedding = np.zeros(50)\n",
    "    for word in q:\n",
    "        if code_unique_words[word] > 10:\n",
    "            q_embedding += code_model[word]\n",
    "    code_q_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(code_q_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_embedding_df = pd.DataFrame((_ for _ in itertools.zip_longest(code_q_embedding)), columns=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df\n",
    "code_embedding_df.to_pickle(\"CodeTextWordEmbeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get top 10 most cosine similar questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Concatenate code and non-code embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code_embedding_df = pd.read_pickle(\"CodeTextWordEmbeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noncode_embedding_df = pd.read_pickle(\"NoncodeTextWordEmbeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noncode_embedding_df.iloc[0,:][0]#.as_matrix()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_embedding = []\n",
    "for i in range(5):# range(noncode_embedding_df.shape[0]):\n",
    "    q_embedding = np.append(noncode_embedding_df.iloc[i,:][0], code_embedding_df.iloc[i,:][0])\n",
    "    combined_embedding.append(q_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get top 10 most cosine similar word embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute cosine similarities of questions\n",
    "# tfidf_question_cosine_similarities = [] # list of indices of top 10 most cosine similar\n",
    "# for i in range(len(questions_lemmatized.index)):\n",
    "#     similarity_indices = cosine_similarity(tfidf_question[i], tfidf_question).flatten()\n",
    "#     tfidf_question_cosine_similarities.append(similarity_indices.argsort()[:-11:-1])\n",
    "\n",
    "\n",
    "# list of indices of top 10 most cosine similar for each question\n",
    "word2vec_question_cosine_similarities = []\n",
    "for i in range(len(combined_embedding)):\n",
    "    similarity_indices = cosine_similarity(combined_embedding[i], combined_embedding).flatten()\n",
    "    word2vec_question_cosine_similarities.append(similarity_indices.argsort()[:-11:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec_question_cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to df\n",
    "word2vec_similarity_df = pd.DataFrame((_ for _ in itertools.zip_longest(word2vec_question_cosine_similarities)), columns=['indices'])\n",
    "word2vec_similarity_df.to_pickle(\"word2vecSimilarity.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
